{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e7833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "from docplex.mp.progress import *\n",
    "from docplex.mp.progress import SolutionRecorder\n",
    "import docplex.mp.model as cpx\n",
    "import networkx as nx\n",
    "import time\n",
    "import random\n",
    "from config import get_config\n",
    "from network import *\n",
    "from work_load import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d68872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def request_service_delay_minimization(self,network,work_load,life_time,iteration,cyclic_workload,storage_capacity,delat_value):        \n",
    "\n",
    "        import docplex.mp.model as cpx\n",
    "        opt_model = cpx.Model(name=\"Storage problem model\"+str(iteration))\n",
    "        w_vars = {}\n",
    "        u_vars = {}\n",
    "\n",
    "        w_vars  = {(t,k,p): opt_model.continuous_var(lb=0, ub= network.max_edge_capacity,\n",
    "                                  name=\"w_{0}_{1}_{2}\".format(t,k,p))  for t in work_load.T \n",
    "                   for k in work_load.each_t_requests[t] \n",
    "                   for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]}\n",
    "\n",
    "        u_vars  = {(t,j,b): opt_model.continuous_var(lb=0, ub= network.max_edge_capacity,\n",
    "                                      name=\"u_{0}_{1}_{2}\".format(t,j,b))  for t in work_load.T \n",
    "                       for j in network.storage_pairs for b in network.each_storage_blocks[j] \n",
    "                   }   \n",
    "\n",
    "        if life_time ==1000:\n",
    "            #inventory evolution constraint\n",
    "            for t in work_load.T[1:]:\n",
    "                for j in network.storage_pairs:\n",
    "                    for b in network.each_storage_blocks[j]:\n",
    "#                         for p_s in network.each_request_real_paths[j,b]:\n",
    "                        if cyclic_workload:\n",
    "                            print(\"testing\",network.each_storage_block_freshness(j,b,delat_value))\n",
    "                            opt_model.add_constraint(u_vars[t,j,b] == u_vars[(t-1)%len(work_load.T),j,b]/network.each_storage_block_freshness(j,b,delat_value)-\n",
    "                            opt_model.sum(w_vars[(t-1)%len(work_load.T),k,p] *\n",
    "                            network.get_required_purification_EPR_pairs(p,work_load.get_each_request_threshold(k,t))\n",
    "                            for k in work_load.each_t_requests[t] if k!=j \n",
    "                            for p in network.each_request_virtual_paths_using_block[k,j,b])*delat_value\n",
    "                            +opt_model.sum(w_vars[(t-1)%len(work_load.T),j,p2] for p2 in network.each_storage_block_paths[j][b])*delat_value\n",
    "                                                 ,ctname=\"inventory_evolution_{0}_{1}_{2}\".format(t,j,b))\n",
    "#                         else:\n",
    "#                             opt_model.add_constraint(u_vars[t,j,b,p_s] == u_vars[t-1,j,b,p_s]/network.each_storage_block_freshness(j,b,delat_value)-\n",
    "#                             opt_model.sum(w_vars[t-1,k,p] *\n",
    "#                             network.get_required_purification_EPR_pairs(p,work_load.get_each_request_threshold(k,t))\n",
    "#                             for k in work_load.each_t_requests[t] if k!=j \n",
    "#                             for p in network.each_request_virtual_paths_include_subpath[k][p_s])*delat_value\n",
    "#                             +opt_model.sum(w_vars[t-1,j,p_s])*delat_value\n",
    "#                                                  , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "        else:\n",
    "            #inventory evolution constraint\n",
    "            for t in work_load.T[1:]:\n",
    "                for j in network.storage_pairs:\n",
    "                    for b in network.each_storage_blocks[j]:\n",
    "                        for p_s in network.each_request_real_paths[j,b]:\n",
    "\n",
    "                            if cyclic_workload:\n",
    "                                opt_model.add_constraint(u_vars[t,j,b,p_s] == -\n",
    "                                opt_model.sum(w_vars[(t-1)%len(work_load.T),k,p] *\n",
    "                                network.get_required_purification_EPR_pairs(p,work_load.get_each_request_threshold(k,t))\n",
    "                                for k in work_load.each_t_requests[t] if k!=j \n",
    "                                for p in network.each_request_virtual_paths_include_subpath[k][p_s] \n",
    "                                )*delat_value\n",
    "                                + opt_model.sum(w_vars[(t-1)%len(work_load.T),j,p_s])*delat_value\n",
    "                                                     , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "                            else:\n",
    "                                opt_model.add_constraint(u_vars[t,j,b,p_s] == -\n",
    "                                opt_model.sum(w_vars[t-1,k,p] *\n",
    "                                network.get_required_purification_EPR_pairs(p,work_load.get_each_request_threshold(k,t))\n",
    "                                for k in work_load.each_t_requests[t] if k!=j \n",
    "                                for p in network.each_request_virtual_paths_include_subpath[k][p_s] \n",
    "                                )*delat_value\n",
    "                                + opt_model.sum(w_vars[t-1,j,p_s])*delat_value\n",
    "                                                     , ctname=\"inventory_evolution_{0}_{1}\".format(t,j,p_s))\n",
    "\n",
    "        # serving from inventory constraint\n",
    "        for t in work_load.T[1:]:\n",
    "            for j in network.storage_pairs:\n",
    "                for b in network.each_storage_blocks[j]:\n",
    "                    opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]*\n",
    "                    network.get_required_purification_EPR_pairs(p,work_load.get_each_request_threshold(k,t))\n",
    "                    for k in work_load.each_t_user_pairs[t] if k!=j \n",
    "                    for p in network.each_request_virtual_paths_using_block[k,j,b]\n",
    "                    )*delat_value<=u_vars[t,j,b]\n",
    "                                         , ctname=\"inventory_serving_{0}_{1}_{2}\".format(t,j,b))  \n",
    "\n",
    "\n",
    "        # Demand constriant\n",
    "        for t in work_load.T[1:]:\n",
    "            for k in  work_load.each_t_requests[t]:\n",
    "                opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "                for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]) >= \n",
    "                        work_load.each_t_each_request_demand[t][k], ctname=\"constraint_{0}_{1}\".format(t,k))\n",
    "\n",
    "        #Edge constraint\n",
    "        for t in work_load.T:\n",
    "            for edge in network.set_E:\n",
    "                opt_model.add_constraint(\n",
    "                    opt_model.sum(w_vars[t,k,p]*network.get_required_purification_EPR_pairs(p,work_load.get_each_request_threshold(k,t)) for k in work_load.each_t_requests[t]\n",
    "                    for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k] if network.check_path_include_edge(edge,p))\n",
    "\n",
    "                     <= network.each_edge_capacity[edge], ctname=\"edge_capacity_{0}_{1}\".format(t,edge))\n",
    "\n",
    "        # storage servers capacity constraint\n",
    "    #     storage_capacity = storage_capacity/delat_value\n",
    "        for t in work_load.T:\n",
    "            #for s1 in network.storage_nodes:\n",
    "            for j in network.storage_pairs:\n",
    "        \n",
    "                opt_model.add_constraint(opt_model.sum(u_vars[t,j,b]\n",
    "                    for b in network.each_storage_blocks[j]) <= storage_capacity \n",
    "            , ctname=\"storage_capacity_constraint_{0}_{1}\".format(t,j))\n",
    "\n",
    "        # constraints for serving from storage at time zero and 1 should be zero\n",
    "#         if not cyclic_workload:\n",
    "#             for t in [0,1]:\n",
    "#                 opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "#                         for k in work_load.each_t_requests[t] for p in network.each_request_virtual_paths[k] \n",
    "#                         )<=0, ctname=\"serving_from_inventory_{0}\".format(t))\n",
    "\n",
    "#         # constraints for putting in storage at time zero  should be zero\n",
    "#         \"\"\"this is becasue we start the formulation from 1 and not from zero and we have t-1 in our formulation\"\"\"\n",
    "#         for t in [0]:\n",
    "#             opt_model.add_constraint(opt_model.sum(w_vars[t,k,p]\n",
    "#                     for k in work_load.each_t_requests[t] for p in network.each_request_real_paths[k] \n",
    "#                     )<=0, ctname=\"storing_in_inventory_{0}\".format(t))   \n",
    "\n",
    "\n",
    "#         # constraint for inventory is zero at time zero \n",
    "#         if not cyclic_workload:\n",
    "#             for t in [0]:\n",
    "#                 for j in network.storage_pairs:\n",
    "#                      for p_s in network.each_request_real_paths[j]:\n",
    "#                             opt_model.add_constraint(u_vars[t,j,p_s] <=0, ctname=\"storage_capacity_constraint_{0}_{1}_{2}\".format(t,j,p_s))\n",
    "\n",
    "        \"\"\"defining an objective, which is a linear expression\"\"\"\n",
    "\n",
    "        objective = opt_model.sum(1/len(work_load.T[1:])*1/len(work_load.each_t_real_requests[t])*1/work_load.each_t_each_request_demand[t][k]\n",
    "                                  *(w_vars[t,k,p] * network.get_path_length(p)) for t in work_load.T[1:]\n",
    "                                  for k in work_load.each_t_user_pairs[t] \n",
    "                                  for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]\n",
    "                                  )\n",
    "\n",
    "\n",
    "\n",
    "        opt_model.minimize(objective)\n",
    "\n",
    "        opt_model.print_information()\n",
    "\n",
    "        opt_model.solve()\n",
    "\n",
    "\n",
    "        print('docplex.mp.solution',opt_model.solution)\n",
    "        objective_value = -1\n",
    "        try:\n",
    "            if opt_model.solution:\n",
    "                objective_value =opt_model.solution.get_objective_value()\n",
    "        except ValueError:\n",
    "            print(ValueError)\n",
    "        each_inventory_per_time_usage = {}\n",
    "        each_time_each_path_delivered_EPRs = {}\n",
    "        each_time_each_path_purification_EPRs = {}\n",
    "        each_time_used_from_storage_EPR_pairs_for_purification = []\n",
    "        each_time_delivered_from_storage_EPR_pairs = []\n",
    "        all_times_all_storages_stored_EPR_pairs = []\n",
    "        if objective_value >0:\n",
    "            if opt_model.solution:\n",
    "                print(\"this has been solved! iteration\",iteration)\n",
    "            print('docplex.mp.solution',opt_model.solution)\n",
    "            #print(\"******************************** start *************************************\")\n",
    "            for t in work_load.T[1:]:\n",
    "                for j in network.storage_pairs:\n",
    "\n",
    "                    for p in network.each_request_real_paths[j]:\n",
    "                        usage_of_storage_pair = 0\n",
    "                        usage_of_storage_pair+=u_vars[t,j,p].solution_value\n",
    "                        #if u_vars[t,j,p].solution_value>0:\n",
    "                            #print(\"u_%s_%s_%s=%s\"%(t,j,p,u_vars[t,j,p].solution_value))\n",
    "                        try:\n",
    "                            each_inventory_per_time_usage[j][t]=u_vars[t,j,p].solution_value\n",
    "                        except:\n",
    "                            try:\n",
    "                                each_inventory_per_time_usage[j][t]=u_vars[t,j,p].solution_value\n",
    "                            except:\n",
    "                                each_inventory_per_time_usage[j] = {}\n",
    "                                each_inventory_per_time_usage[j][t]=u_vars[t,j,p].solution_value        \n",
    "                        all_times_all_storages_stored_EPR_pairs.append(usage_of_storage_pair)\n",
    "\n",
    "            #print(\"******************************** end *************************************\")   \n",
    "\n",
    "            for t in work_load.T:\n",
    "                u_value = 0\n",
    "                for j in network.storage_pairs:\n",
    "                    for p in network.each_request_real_paths[j]:\n",
    "                        if storage_capacity< int(u_vars[t,j,p].solution_value)-1:\n",
    "                            print(\"THIS IS a BIG ERROR!!!\",u_vars[t,j,p].solution_value , storage_capacity)\n",
    "                            import pdb\n",
    "                            pdb.set_trace()\n",
    "\n",
    "\n",
    "                    #if u_value > storage_capacity:\n",
    "                        #print(\"Error!!!!!\")\n",
    "                        #print(\"u value for storage %s is %s  and we have capacity as %s\"%(s1,u_value,storage_capacity))\n",
    "                        #import pdb\n",
    "                        #pdb.set_trace()\n",
    "                    #else:\n",
    "                        #print(\"OK!\")\n",
    "\n",
    "\n",
    "        if objective_value>0:\n",
    "            for t in work_load.T[1:]:\n",
    "                for k in work_load.each_t_real_requests[t]: \n",
    "                    for p in network.each_request_virtual_paths[k]:\n",
    "                        try:\n",
    "                            each_time_delivered_from_storage_EPR_pairs.append(w_vars[t,k,p].solution_value)\n",
    "                        except:\n",
    "                            each_time_delivered_from_storage_EPR_pairs=[w_vars[t,k,p].solution_value]\n",
    "                        purification_EPR_pairs = network.get_required_purification_EPR_pairs(p,work_load.get_each_request_threshold(k,t))\n",
    "                        try:\n",
    "                            each_time_used_from_storage_EPR_pairs_for_purification.append(purification_EPR_pairs)\n",
    "                        except:\n",
    "                            each_time_used_from_storage_EPR_pairs_for_purification=[purification_EPR_pairs]\n",
    "            for t in work_load.T[1:]:\n",
    "                for k in work_load.each_t_real_requests[t]: \n",
    "                    for p in network.each_request_real_paths[k]+network.each_request_virtual_paths[k]:\n",
    "                        try:\n",
    "                            each_time_each_path_delivered_EPRs[t][k]+=w_vars[t,k,p].solution_value\n",
    "                        except:\n",
    "                            try:\n",
    "                                each_time_each_path_delivered_EPRs[t][k]= w_vars[t,k,p].solution_value\n",
    "                            except:\n",
    "                                each_time_each_path_delivered_EPRs[t]={}\n",
    "                                each_time_each_path_delivered_EPRs[t][k]= w_vars[t,k,p].solution_value\n",
    "\n",
    "                        try:\n",
    "                            each_time_each_path_purification_EPRs[t][k]+=network.get_required_purification_EPR_pairs(p,work_load.get_each_request_threshold(k,t))\n",
    "                        except:\n",
    "                            try:\n",
    "                                each_time_each_path_purification_EPRs[t][k]= network.get_required_purification_EPR_pairs(p,work_load.get_each_request_threshold(k,t))\n",
    "                            except:\n",
    "                                each_time_each_path_purification_EPRs[t]={}\n",
    "                                each_time_each_path_purification_EPRs[t][k]= network.get_required_purification_EPR_pairs(p,work_load.get_each_request_threshold(k,t))        \n",
    "\n",
    "        opt_model.clear()\n",
    "        return objective_value,all_times_all_storages_stored_EPR_pairs,each_time_delivered_from_storage_EPR_pairs,each_time_used_from_storage_EPR_pairs_for_purification\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8056d2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#paths: 0:(0,1),(1,2),(2,3),(3,4),(4,5),\n",
    "        #1:(1,2),(2,3),(3,4),\n",
    "        #2:(0,1),(1,4),(4,5)\n",
    "        \n",
    "\n",
    "network = Network()\n",
    "network.set_of_paths = {0:[0,1,2,3,4],1:[1,2,3],2:[0,5]}\n",
    "\n",
    "\n",
    "network.max_edge_capacity =100\n",
    "network.fidelity_threshold_values = [0.9,0.94,0.95,0.98]\n",
    "\n",
    "network.each_path_basic_fidelity  ={0:0.8,1:0.9,2:0.8}\n",
    "network.oracle_for_target_fidelity = {}\n",
    "network.set_required_EPR_pairs_for_each_path_each_fidelity_threshold()\n",
    "\n",
    "\n",
    "network.each_request_real_paths = {0:[0]}\n",
    "network.each_request_virtual_paths_using_block = {0:{0:{0:1}}}\n",
    "\n",
    "\n",
    "network.each_request_virtual_paths = {0:[1]}\n",
    "network.storage_pairs = [0]\n",
    "network.each_storage_blocks ={0:[0]} \n",
    "network.each_request_real_paths = {0:[1]}\n",
    "network.each_storage_block_paths = {0:{0:[1]}}\n",
    "\n",
    "#Edge constraint\n",
    "network.set_E = [0,1,2,3,4,5]\n",
    "network.each_edge_capacity = {0:100,1:100,2:100,3:100,4:100,5:100}\n",
    "\n",
    "storage_capacity  = 500\n",
    "          \n",
    "    \n",
    "    \n",
    "work_load = Work_load()\n",
    "work_load.each_t_user_pairs = {0:[0],1:[0],2:[0],3:[0]}\n",
    "work_load.T  = [0,1,2,3]\n",
    "work_load.each_t_requests = {0:[0],1:[0],2:[0],3:[0],4:[0]} \n",
    "# Demand constriant\n",
    "work_load.each_t_each_request_demand = {0:{0:5},1:{0:20},\n",
    "                                        2:{0:5},3:{0:10}}    \n",
    "work_load.each_request_threshold = {0:{0:0.9,1:0.9,2:0.9,3:0.9}}\n",
    "work_load.each_t_real_requests = {0:[0],1:[0],2:[0],3:[0],4:[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3cb3b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Duplicate variable name: w_0_0_1 already used for docplex.mp.Var(type=C,name='w_0_0_1',ub=100)\n",
      "Warning: Duplicate variable name: w_1_0_1 already used for docplex.mp.Var(type=C,name='w_1_0_1',ub=100)\n",
      "Warning: Duplicate variable name: w_2_0_1 already used for docplex.mp.Var(type=C,name='w_2_0_1',ub=100)\n",
      "Warning: Duplicate variable name: w_3_0_1 already used for docplex.mp.Var(type=C,name='w_3_0_1',ub=100)\n",
      "testing 1\n",
      "testing 1\n",
      "testing 1\n",
      "Model: Storage problem model0\n",
      " - number of variables: 12\n",
      "   - binary=0, integer=0, continuous=12\n",
      " - number of constraints: 37\n",
      "   - linear=37\n",
      " - parameters: defaults\n",
      " - objective: minimize\n"
     ]
    },
    {
     "ename": "DOcplexException",
     "evalue": "Cannot solve model: no CPLEX runtime found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDOcplexException\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m solver \u001b[38;5;241m=\u001b[39mSolver()\n\u001b[0;32m----> 2\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_service_delay_minimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwork_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                          \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mSolver.request_service_delay_minimization\u001b[0;34m(self, network, work_load, life_time, iteration, cyclic_workload, storage_capacity, delat_value)\u001b[0m\n\u001b[1;32m    140\u001b[0m opt_model\u001b[38;5;241m.\u001b[39mminimize(objective)\n\u001b[1;32m    142\u001b[0m opt_model\u001b[38;5;241m.\u001b[39mprint_information()\n\u001b[0;32m--> 144\u001b[0m \u001b[43mopt_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocplex.mp.solution\u001b[39m\u001b[38;5;124m'\u001b[39m,opt_model\u001b[38;5;241m.\u001b[39msolution)\n\u001b[1;32m    148\u001b[0m objective_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/docplex/mp/model.py:4828\u001b[0m, in \u001b[0;36mModel.solve\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   4826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solve_local(context, used_clean_before_solve, parameter_sets)\u001b[38;5;66;03m# lex_timelimits, lex_mipgaps)\u001b[39;00m\n\u001b[1;32m   4827\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfatal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCannot solve model: no CPLEX runtime found.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/docplex/mp/model.py:1078\u001b[0m, in \u001b[0;36mModel.fatal\u001b[0;34m(self, msg, *args)\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfatal\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1078\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_error_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfatal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/docplex/mp/error_handler.py:210\u001b[0m, in \u001b[0;36mAbstractErrorHandler.fatal\u001b[0;34m(self, msg, args)\u001b[0m\n\u001b[1;32m    208\u001b[0m resolved_message \u001b[38;5;241m=\u001b[39m resolve_pattern(msg, args)\n\u001b[1;32m    209\u001b[0m docplex_error_stop_here()\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m DOcplexException(resolved_message)\n",
      "\u001b[0;31mDOcplexException\u001b[0m: Cannot solve model: no CPLEX runtime found."
     ]
    }
   ],
   "source": [
    "solver =Solver()\n",
    "solver.request_service_delay_minimization(network,work_load,\n",
    "                                          1000,0,True,100,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e8520b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
