{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from itertools import islice\n",
    "import random\n",
    "from itertools import groupby\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import pdb\n",
    "from network import *\n",
    "from work_load import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d300dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "\n",
    "work_load = Work_load()\n",
    "\n",
    "network.computing_blocks_of_qubits() \n",
    "for i in range(100):\n",
    "     for edge_fidelity_range in edge_fidelity_ranges:\n",
    "        for network_topology,file_path in each_network_topology_file.items():\n",
    "            for spike_mean in each_topology_mean_value_spike[network_topology]:\n",
    "                work_load.generat_demands()\n",
    "                each_storage_each_path_number_value = {}\n",
    "                network = Network(config,file_path,False,edge_fidelity_range,max_edge_capacity_value,fidelity_threshold_ranges)\n",
    "                for T in T_values:\n",
    "                    for i in range(experiment_repeat):\n",
    "                        for storage_capacity in storage_capacities:\n",
    "                            for fidelity_threshold_range in fidelity_threshold_ranges:\n",
    "                                for storage_node_selection_scheme in storage_node_selection_schemes:\n",
    "                                    selected_storage_nodes = []\n",
    "                                    selected_storage_pairs = []\n",
    "                                    for num_paths in [1]:\n",
    "                                        for number_of_storages in [0,2,4,8,10]:\n",
    "                                            \"\"\"with new storage pairs, we will check the solution for each number of paths(real and virtual)\"\"\"\n",
    "                                            pairs = []\n",
    "                                            network.setup_network()\n",
    "                                            for delat_value in delat_values:\n",
    "                                                for life_time in given_life_time_set:\n",
    "                                                    for purificaion_scheme in purification_schemes:\n",
    "                                                        objective_value=-1\n",
    "                                                        if network.path_existance_flag:\n",
    "                                                            try:\n",
    "                                                                solver.request_service_delay_minimization()\n",
    "                                                            except:\n",
    "                                                                objective_value = -1\n",
    "                                                        else:\n",
    "                                                            print(\"oops we do not have even one path for one k at a time!!\")\n",
    "                                                            objective_value = -1\n",
    "\n",
    "\n",
    "                                                    print(\"for purificaion %s topology %s iteration %s from %s spike mean %s capacity %s  fidelity range %s  life time %s storage %s and path number %s objective_value %s\"%\n",
    "                                                    (purificaion_scheme,network_topology,i,experiment_repeat, spike_mean,storage_capacity,fidelity_threshold_range,life_time, number_of_storages,num_paths, objective_value))  \n",
    "\n",
    "                                                    with open(results_file_path, 'a') as newFile:                                \n",
    "                                                        newFileWriter = csv.writer(newFile)\n",
    "                                                        newFileWriter.writerow([network_topology,number_of_storages,num_paths,\n",
    "                                                                                life_time,\n",
    "                                                                                objective_value,spike_mean,num_spikes,i,\n",
    "                                                                                storage_node_selection_scheme,\n",
    "                                                                                fidelity_threshold_range,cyclic_workload,\n",
    "                                                                                distance_between_users,storage_capacity,edge_fidelity_range,delat_value,purificaion_scheme]) \n",
    "                                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031be1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EGR_for_dynamic_population(each_network_topology_file,spike_mean,num_spikes,experiment_repeat,storage_node_selection_scheme):\n",
    "    for spike_mean in spike_means:\n",
    "        for network_topology,file_path in each_network_topology_file.items():\n",
    "            import pdb\n",
    "            each_storage_each_path_number_value = {}\n",
    "            network = Network(file_path)\n",
    "            \n",
    "            for i in range(experiment_repeat):\n",
    "        \n",
    "                network = Network(file_path)\n",
    "                network.get_user_pairs_over_dynamicly_chaning_population(number_of_user_pairs,distance_between_users,number_of_time_slots)\n",
    "\n",
    "                work_load = Work_load(number_of_time_slots,\"time_demands_file.csv\")\n",
    "\n",
    "                objective_values = []\n",
    "                selected_storage_nodes = []\n",
    "                selected_storage_pairs = []\n",
    "\n",
    "                #nx.draw(network.g,with_labels=True)\n",
    "                # plt.show()\n",
    "                network.reset_pair_paths()\n",
    "                pairs = []\n",
    "                print(\"network.each_t_user_pairs\",network.each_t_user_pairs)\n",
    "                for t,user_pairs in network.each_t_user_pairs.items():            \n",
    "                    for user_pair in user_pairs:\n",
    "                        if user_pair not in pairs:\n",
    "                            pairs.append(user_pair)\n",
    "                network.get_each_user_pair_real_paths(pairs)\n",
    "\n",
    "                import pdb\n",
    "                #pdb.set_trace()\n",
    "\n",
    "\n",
    "                \"\"\"select and add new storage pairs\"\"\"\n",
    "\n",
    "                for number_of_storages in range(7):\n",
    "                    print(\"for number of storages round  \",number_of_storages)\n",
    "                    network.get_new_storage_pairs(number_of_storages,storage_node_selection_scheme)\n",
    "                    work_load.reset_variables()\n",
    "                    work_load.set_each_time_requests(network.each_t_user_pairs,network.storage_pairs)\n",
    "                    work_load.set_each_time_real_requests(network.each_t_user_pairs)\n",
    "                    \"\"\"with new storage pairs, we will check the solution for each number of paths(real and virtual)\"\"\"\n",
    "                    for num_paths in range(3,4):\n",
    "\n",
    "                        path_counter_id = 0\n",
    "                        #print(\"network.storage_pairs\",network.storage_pairs)\n",
    "                        #import pdb\n",
    "                        #pdb.set_trace()\n",
    "                        network.get_each_user_pair_real_paths(network.storage_pairs)\n",
    "                        if number_of_storages==1:\n",
    "                            number_of_storages = 2\n",
    "\n",
    "                        \"\"\"first we add the real paths between storage pairs\"\"\"\n",
    "\n",
    "                        print(\"for iteration %s storage %s and path number %s\"%(i,number_of_storages,num_paths))\n",
    "                        for storage_pair in network.storage_pairs:\n",
    "                            #print(\"going to get real paths between storage pair \",storage_pair)\n",
    "                            paths = network.get_real_path(storage_pair,num_paths)\n",
    "                            #print(\"got paths\",paths)\n",
    "                            for path in paths:\n",
    "                                network.set_each_path_length(path_counter_id,path)\n",
    "                                network.set_of_paths[path_counter_id] = path\n",
    "                                network.each_path_path_id[tuple(path)] = path_counter_id\n",
    "                                try:\n",
    "                                    network.each_request_real_paths[storage_pair].append(path_counter_id)\n",
    "                                except:\n",
    "                                    network.each_request_real_paths[storage_pair]=[path_counter_id]\n",
    "                                try:\n",
    "                                    network.each_storage_real_paths[storage_pair].append(path)\n",
    "                                except:\n",
    "                                    network.each_storage_real_paths[storage_pair]=[path]\n",
    "                                #print(\"*** we used path_counter_id\",path_counter_id)\n",
    "                                path_counter_id+=1\n",
    "\n",
    "                        across_all_time_slots_pairs = []\n",
    "                        for t,user_pairs in network.each_t_user_pairs.items():\n",
    "                            for user_pair in user_pairs:\n",
    "                                if user_pair not in across_all_time_slots_pairs:\n",
    "                                    across_all_time_slots_pairs.append(user_pair)\n",
    "                        all_sub_paths = []\n",
    "                        for user_pair in across_all_time_slots_pairs:\n",
    "                            paths = network.get_real_path(user_pair,num_paths)\n",
    "                            #print(\"we got real paths for user pair\",user_pair,paths)\n",
    "                            for path in paths:\n",
    "                                network.set_of_paths[path_counter_id] = path\n",
    "                                network.set_each_path_length(path_counter_id,path)\n",
    "                                network.each_path_path_id[tuple(path)] = path_counter_id\n",
    "                                try:\n",
    "                                    network.each_request_real_paths[user_pair].append(path_counter_id)\n",
    "                                except:\n",
    "                                    network.each_request_real_paths[user_pair]=[path_counter_id]\n",
    "                                \n",
    "                                path_counter_id+=1\n",
    "    \n",
    "                            for storage_pair in network.storage_pairs:\n",
    "                                \"\"\"add one new path to the previous paths\"\"\"\n",
    "                                for real_sub_path in network.each_storage_real_paths[storage_pair]:\n",
    "                                    \n",
    "                                    paths = network.get_paths_to_connect_users_to_storage(user_pair,real_sub_path,num_paths)\n",
    "    #                               \n",
    "                                    this_sub_path_id = network.each_path_path_id[tuple(real_sub_path)]\n",
    "                                    \n",
    "\n",
    "                                    for path in paths:\n",
    "                                        network.set_each_path_length(path_counter_id,path)\n",
    "                                        \"\"\"we remove the sub path that is connecting two storage pairs \n",
    "                                        from the path because we do not want to check the edge capacity for the edges of this subpath\"\"\"\n",
    "    #                                     print(\"we set length %s for path %s having sub path %s with ID %s\"%(len(path),path,real_sub_path,this_sub_path_id))\n",
    "                                        try:\n",
    "                                            network.each_request_virtual_paths_include_subpath[user_pair][this_sub_path_id].append(path_counter_id)\n",
    "                                        except:\n",
    "                                            try:\n",
    "                                                network.each_request_virtual_paths_include_subpath[user_pair][this_sub_path_id]=[path_counter_id]\n",
    "                                            except:\n",
    "                                                network.each_request_virtual_paths_include_subpath[user_pair]={}\n",
    "                                                network.each_request_virtual_paths_include_subpath[user_pair][this_sub_path_id]=[path_counter_id]\n",
    "                                        if this_sub_path_id not in all_sub_paths:\n",
    "                                            all_sub_paths.append(this_sub_path_id)\n",
    "                                        path = network.remove_storage_pair_real_path_from_path(real_sub_path,path)\n",
    "                                        #print(\"and after removing sub path we have \",path,real_sub_path,len(path))\n",
    "                                        network.set_of_paths[path_counter_id] = path\n",
    "                                        try:\n",
    "                                            network.each_request_virtual_paths[user_pair].append(path_counter_id)\n",
    "                                        except:\n",
    "                                            network.each_request_virtual_paths[user_pair]=[path_counter_id]\n",
    "                                        #print(\"*** we used path_counter_id\",path_counter_id)\n",
    "                                        path_counter_id+=1\n",
    "\n",
    "\n",
    "                                    for pair in network.storage_pairs:\n",
    "                                        network.each_request_virtual_paths[pair]=[]\n",
    "\n",
    "                                    #print(\"for user pair %s to storage pair %s we got real paths and it is:\"%(user_pair,storage_pair))\n",
    "\n",
    "                        if number_of_storages==0:\n",
    "                            for t,pairs in network.each_t_user_pairs.items():\n",
    "                                for pair in pairs:\n",
    "                                    network.each_request_virtual_paths[pair]=[]\n",
    "\n",
    "                        for j in network.storage_pairs:\n",
    "                            for sub_path_id in all_sub_paths:\n",
    "                                try:\n",
    "                                    network.each_request_virtual_paths_include_subpath[j][sub_path_id] = []\n",
    "                                except:\n",
    "                                    network.each_request_virtual_paths_include_subpath[j]={}\n",
    "                                    network.each_request_virtual_paths_include_subpath[j][sub_path_id] = []\n",
    "                        for t in range(number_of_time_slots):\n",
    "                            for k in work_load.each_t_requests[t]:\n",
    "                                try:\n",
    "                                    if k in list(network.each_request_virtual_paths_include_subpath.keys()):\n",
    "                                        pass\n",
    "                                    else:\n",
    "                                        network.each_request_virtual_paths_include_subpath[k]= {}\n",
    "                                except:\n",
    "                                    network.each_request_virtual_paths_include_subpath[k]= {}\n",
    "\n",
    "                        \"\"\"we set the capacity of each storage node\"\"\"\n",
    "\n",
    "                        network.set_storage_capacity()\n",
    "\n",
    "                        \"\"\"we add new storage pairs as our user pairs and set the demand for them zero\"\"\"\n",
    "\n",
    "                        work_load.set_storage_pairs_as_user_pairs(network.storage_pairs)\n",
    "\n",
    "                        \"\"\"we print all variables to check the variables and values\"\"\"\n",
    "\n",
    "                        life_time_set = [1000,2]\n",
    "                        for life_time in life_time_set:\n",
    "                            \"\"\"solve the optimization\"\"\"        \n",
    "                            try:\n",
    "                                objective_value=0\n",
    "                                try:\n",
    "                                    objective_value,each_inventory_per_time_usage = CPLEX_maximizing_entanglement_generation(network,work_load,life_time,i)\n",
    "                                except ValueError:\n",
    "                                    print(ValueError)\n",
    "                                    pass\n",
    "                                objective_values.append(objective_value)\n",
    "                                if 0<objective_value<distance_between_users-1:\n",
    "                                    \n",
    "\n",
    "                                print(\"the objective value for %s storage nodes and %s paths between each pair of nodes is %s\"%(number_of_storages,num_paths,objective_value))\n",
    "\n",
    "    #                             print(each_inventory_per_time_usage)\n",
    "                                #time.sleep(10)\n",
    "                                for storage_pair,t_saved_EPRs in each_inventory_per_time_usage.items():\n",
    "                                    for t ,EPRs in t_saved_EPRs.items():\n",
    "                                        with open(inventory_utilization_results_file_path, 'a') as newFile:                                \n",
    "                                            newFileWriter = csv.writer(newFile)\n",
    "                                            newFileWriter.writerow([topology,number_of_storages,num_paths,i,life_time,storage_pair,t,EPRs,storage_node_selection_scheme]) \n",
    "\n",
    "                                with open(results_file_path, 'a') as newFile:                                \n",
    "                                    newFileWriter = csv.writer(newFile)\n",
    "                                    newFileWriter.writerow([topology,number_of_storages,num_paths,life_time,objective_value,i,storage_node_selection_scheme]) \n",
    "\n",
    "                            except ValueError:\n",
    "                                #pass\n",
    "                                print(ValueError)\n",
    "                print(\"until the %s th iteration we have %s\"%(i,each_storage_each_path_number_value)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f6746",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_repeat =50\n",
    "spike_means = [300,250,280,350]\n",
    "num_spikes = 2\n",
    "topology_set = sys.argv[1]\n",
    "distance_between_users = int(sys.argv[2])\n",
    "storage_node_selection_schemes=[\"Degree\",\"Random\"]\n",
    "storage_node_selection_schemes=[\"Degree\",\"Random\"]\n",
    "cyclic_workload = \"sequential\"\n",
    "storage_capacities = [400,50,100,200]\n",
    "fidelity_threshold_ranges = [0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.98,1.0]\n",
    "\n",
    "\n",
    "given_life_time_set = [2,1000]\n",
    "number_of_user_pairs =3\n",
    "number_of_time_slots = 15\n",
    "results_file_path = 'results/results_feasibility.csv'\n",
    "inventory_utilization_results_file_path = 'results/inventory_feasibility_utilization.csv'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
