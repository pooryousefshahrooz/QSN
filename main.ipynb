{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dcc5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from itertools import islice\n",
    "import random\n",
    "from itertools import groupby\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pdb\n",
    "from network import *\n",
    "from work_load import *\n",
    "from solver import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4bb60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths: 0:(0,1),(1,2),(2,3),(3,4),(4,5),\n",
    "        #1:(1,2),(2,3),(3,4),\n",
    "        #2:(0,1),(1,4),(4,5)\n",
    "        \n",
    "# 0:(0,1),1:(1,2),2:(2,3),3:(3,4),4:(4,5),5:(5,6)\n",
    "network = Network()\n",
    "network.set_of_paths = {0:[0,1,2,3,4,5],1:[1,2,3],2:[0,5]}\n",
    "network.each_edge_fidelity = {0:0.94,1:0.94,2:0.94,3:0.94,4:0.94,5:0.94}\n",
    "network.max_edge_capacity =800\n",
    "network.each_request_real_paths = {0:[0],1:[1]}\n",
    "network.each_request_virtual_paths = {0:[2],1:[]}\n",
    "network.each_request_each_storage_each_block_paths = {0:\n",
    "                                                      {1:\n",
    "                                                       {0:[2]}\n",
    "                                                      }}\n",
    "\n",
    "\n",
    "network.storage_pairs = [1]\n",
    "network.each_storage_blocks ={1:[0]} \n",
    "network.each_storage_block_paths = {1:{0:[1]}}\n",
    "\n",
    "#Edge constraint\n",
    "network.set_E = [0,1,2,3,4,5]\n",
    "network.each_edge_capacity = {0:1200,1:600,2:600,3:600,4:600,5:1200}\n",
    "\n",
    "work_load = Work_load()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5a08cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Storage problem model0\n",
      " - number of variables: 40\n",
      "   - binary=0, integer=0, continuous=40\n",
      " - number of constraints: 97\n",
      "   - linear=97\n",
      " - parameters: defaults\n",
      " - objective: minimize\n"
     ]
    },
    {
     "ename": "DOcplexException",
     "evalue": "Cannot solve model: no CPLEX runtime found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDOcplexException\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m delta_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     46\u001b[0m     solver \u001b[38;5;241m=\u001b[39mSolver()\n\u001b[0;32m---> 47\u001b[0m     service_delay \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_service_delay_minimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwork_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mstorage_capacity\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdelta_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     line_items \u001b[38;5;241m=\u001b[39m [t_max,request_fidelity_threshold,\n\u001b[1;32m     50\u001b[0m                   storage_block_threshold,\n\u001b[1;32m     51\u001b[0m                   storage_capacity,i,τ_coh,service_delay]\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(results_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m newFile:                                \n",
      "File \u001b[0;32m~/PhD_research_projects/QSN/solver.py:168\u001b[0m, in \u001b[0;36mSolver.request_service_delay_minimization\u001b[0;34m(self, network, work_load, life_time, iteration, cyclic_workload, storage_capacity, delat_value)\u001b[0m\n\u001b[1;32m    164\u001b[0m opt_model\u001b[38;5;241m.\u001b[39mminimize(objective)\n\u001b[1;32m    166\u001b[0m opt_model\u001b[38;5;241m.\u001b[39mprint_information()\n\u001b[0;32m--> 168\u001b[0m \u001b[43mopt_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocplex.mp.solution\u001b[39m\u001b[38;5;124m'\u001b[39m,opt_model\u001b[38;5;241m.\u001b[39msolution)\n\u001b[1;32m    172\u001b[0m objective_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/docplex/mp/model.py:4828\u001b[0m, in \u001b[0;36mModel.solve\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   4826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solve_local(context, used_clean_before_solve, parameter_sets)\u001b[38;5;66;03m# lex_timelimits, lex_mipgaps)\u001b[39;00m\n\u001b[1;32m   4827\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfatal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCannot solve model: no CPLEX runtime found.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/docplex/mp/model.py:1078\u001b[0m, in \u001b[0;36mModel.fatal\u001b[0;34m(self, msg, *args)\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfatal\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1078\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_error_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfatal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/docplex/mp/error_handler.py:210\u001b[0m, in \u001b[0;36mAbstractErrorHandler.fatal\u001b[0;34m(self, msg, args)\u001b[0m\n\u001b[1;32m    208\u001b[0m resolved_message \u001b[38;5;241m=\u001b[39m resolve_pattern(msg, args)\n\u001b[1;32m    209\u001b[0m docplex_error_stop_here()\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m DOcplexException(resolved_message)\n",
      "\u001b[0;31mDOcplexException\u001b[0m: Cannot solve model: no CPLEX runtime found."
     ]
    }
   ],
   "source": [
    "results_file_path = \"../QSN_results_final_maximizing_rate.csv\"\n",
    "τ_coh_list = np.logspace(1,2,20)\n",
    "instance_counter = 0\n",
    "number_of_experiments = 400\n",
    "request_fidelity_thresholds = [0.6,0.7,0.9,0.8,0.94]\n",
    "storage_block_thresholds  = [0.7,0.9,0.95,0.8,0.85]\n",
    "storage_capacities = [i for i in range(100,500,100)]\n",
    "t_max_list = [t for t in range(10,50,10)]\n",
    "delta_values = [d for d in range(2,20,2)]\n",
    "demand_max = 50\n",
    "feasibility_flag = False\n",
    "all_instances = (len(t_max_list)*number_of_experiments*\n",
    "                 len(request_fidelity_thresholds)*\n",
    "                 len(storage_block_thresholds)*len(storage_capacities)*\n",
    "                 len(τ_coh_list)*len(delta_values))\n",
    "start_time = time.time()\n",
    "for t_max in t_max_list:\n",
    "    for i in range(number_of_experiments):\n",
    "        for request_fidelity_threshold in request_fidelity_thresholds:\n",
    "            if request_fidelity_threshold not in network.fidelity_threshold_values:\n",
    "                network.fidelity_threshold_values.append(request_fidelity_threshold)\n",
    "                    \n",
    "            work_load.each_t_user_pairs={}\n",
    "            work_load.T = []\n",
    "            work_load.each_t_requests={}\n",
    "            for t in range(0,t_max):\n",
    "                work_load.each_t_user_pairs[t]=[0]\n",
    "                work_load.T.append(t)\n",
    "                work_load.each_t_requests[t]=[0,1]\n",
    "                try:\n",
    "                    work_load.each_request_each_time_threshold[0][t]=request_fidelity_threshold\n",
    "                except:\n",
    "                    work_load.each_request_each_time_threshold[0]={}\n",
    "                    work_load.each_request_each_time_threshold[0][t]=request_fidelity_threshold\n",
    "                work_load.each_t_real_requests[t] = [0]\n",
    "\n",
    "            for storage_block_threshold in storage_block_thresholds:\n",
    "                for t in range(0,t_max):\n",
    "                    try:\n",
    "                        network.each_storage_block_time_treshold[1][0][t]=storage_block_threshold\n",
    "                    except:\n",
    "                        try:\n",
    "                            network.each_storage_block_time_treshold[1][0][t]=storage_block_threshold\n",
    "                            network.each_storage_block_time_treshold[1][0][t]=storage_block_threshold\n",
    "                        except:\n",
    "                            network.each_storage_block_time_treshold[1]={}\n",
    "                            network.each_storage_block_time_treshold[1][0]={}\n",
    "                            network.each_storage_block_time_treshold[1][0][t]=storage_block_threshold\n",
    "                if storage_block_threshold not in network.fidelity_threshold_values:\n",
    "                    network.fidelity_threshold_values.append(storage_block_threshold)\n",
    "                network.set_each_path_basic_fidelity(storage_block_threshold)\n",
    "                network.oracle_for_target_fidelity = {}\n",
    "#                 for path,b_f in network.each_path_basic_fidelity.items():\n",
    "#                     print(path,b_f)\n",
    "                        \n",
    "                network.set_required_EPR_pairs_for_each_path_each_fidelity_threshold()\n",
    "\n",
    "                # Demand constriant\n",
    "                work_load.each_t_each_request_demand = {}\n",
    "                work_load.set_each_user_pair_demands(len(work_load.T),work_load.each_t_user_pairs,demand_max,2)\n",
    "#                 print(\"work_load.each_t_each_request_demand\",work_load.each_t_each_request_demand)\n",
    "                for storage_capacity in storage_capacities:\n",
    "                    for idx,τ_coh in enumerate(τ_coh_list):\n",
    "                        network.τ_coh = τ_coh\n",
    "                        for delta_value in delta_values:\n",
    "                            \n",
    "#                             for path,b_f in network.each_path_basic_fidelity.items():\n",
    "#                                 print(path,b_f,network.oracle_for_target_fidelity[path])\n",
    "                            \n",
    "                            solver =Solver()\n",
    "                            service_delay = solver.request_service_delay_minimization(network,work_load,\n",
    "                                                                      1000,i,True,storage_capacity,delta_value,\n",
    "                                                                                     feasibility_flag)\n",
    "                            line_items = [t_max,i,request_fidelity_threshold,\n",
    "                                          storage_block_threshold,\n",
    "                                          storage_capacity,τ_coh,delta_value,service_delay,\n",
    "                                          network.each_edge_capacity[1],demand_max,\n",
    "                                          feasibility_flag\n",
    "                                         ]\n",
    "                            with open(results_file_path, 'a') as newFile:                                \n",
    "                                            newFileWriter = csv.writer(newFile)\n",
    "                                            newFileWriter.writerow([item for item in line_items])\n",
    "                                        \n",
    "                            instance_counter+=1\n",
    "                            end_time = time.time()\n",
    "                            duration = round(end_time -start_time,4)\n",
    "                            start_time = time.time()\n",
    "                            print(\"%s / %s d = %s k for t_max %s exp %s req.Fth %s S.Blk.Fth %s stg_C %s τ_coh %s dlta %s \"%(instance_counter,\n",
    "                                                                        all_instances/1000,duration,t_max,\n",
    "                                                                          i,request_fidelity_threshold,\n",
    "                                                                        storage_block_threshold,\n",
    "                                                                        storage_capacity,\n",
    "                                                                    round(τ_coh,3),delta_value\n",
    "                                                                         ),end=\"\\r\")\n",
    "                            \n",
    "#                             time.sleep(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f5665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[ 10.          10.82636734  11.72102298  12.68961003  13.73823796\n",
      "  14.87352107  16.10262028  17.43328822  18.87391822  20.43359718\n",
      "  22.12216291  23.9502662   25.92943797  28.07216204  30.39195382\n",
      "  32.90344562  35.6224789   38.56620421  41.75318937  45.20353656\n",
      "  48.93900918  52.98316906  57.3615251   62.10169419  67.23357536\n",
      "  72.78953844  78.80462816  85.31678524  92.36708572 100.        ]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d300dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = Network()\n",
    "\n",
    "# work_load = Work_load()\n",
    "\n",
    "# network.computing_blocks_of_qubits() \n",
    "# for i in range(100):\n",
    "#      for edge_fidelity_range in edge_fidelity_ranges:\n",
    "#         for network_topology,file_path in each_network_topology_file.items():\n",
    "#             for spike_mean in each_topology_mean_value_spike[network_topology]:\n",
    "#                 work_load.generat_demands()\n",
    "#                 each_storage_each_path_number_value = {}\n",
    "#                 network = Network(config,file_path,False,edge_fidelity_range,max_edge_capacity_value,fidelity_threshold_ranges)\n",
    "#                 for T in T_values:\n",
    "#                     for i in range(experiment_repeat):\n",
    "#                         for storage_capacity in storage_capacities:\n",
    "#                             for fidelity_threshold_range in fidelity_threshold_ranges:\n",
    "#                                 for storage_node_selection_scheme in storage_node_selection_schemes:\n",
    "#                                     selected_storage_nodes = []\n",
    "#                                     selected_storage_pairs = []\n",
    "#                                     for num_paths in [1]:\n",
    "#                                         for number_of_storages in [0,2,4,8,10]:\n",
    "#                                             \"\"\"with new storage pairs, we will check the solution for each number of paths(real and virtual)\"\"\"\n",
    "#                                             pairs = []\n",
    "#                                             network.setup_network()\n",
    "#                                             for delat_value in delat_values:\n",
    "#                                                 for life_time in given_life_time_set:\n",
    "#                                                     for purificaion_scheme in purification_schemes:\n",
    "#                                                         objective_value=-1\n",
    "#                                                         if network.path_existance_flag:\n",
    "#                                                             try:\n",
    "#                                                                 solver.request_service_delay_minimization()\n",
    "#                                                             except:\n",
    "#                                                                 objective_value = -1\n",
    "#                                                         else:\n",
    "#                                                             print(\"oops we do not have even one path for one k at a time!!\")\n",
    "#                                                             objective_value = -1\n",
    "\n",
    "\n",
    "#                                                     print(\"for purificaion %s topology %s iteration %s from %s spike mean %s capacity %s  fidelity range %s  life time %s storage %s and path number %s objective_value %s\"%\n",
    "#                                                     (purificaion_scheme,network_topology,i,experiment_repeat, spike_mean,storage_capacity,fidelity_threshold_range,life_time, number_of_storages,num_paths, objective_value))  \n",
    "\n",
    "#                                                     with open(results_file_path, 'a') as newFile:                                \n",
    "#                                                         newFileWriter = csv.writer(newFile)\n",
    "#                                                         newFileWriter.writerow([network_topology,number_of_storages,num_paths,\n",
    "#                                                                                 life_time,\n",
    "#                                                                                 objective_value,spike_mean,num_spikes,i,\n",
    "#                                                                                 storage_node_selection_scheme,\n",
    "#                                                                                 fidelity_threshold_range,cyclic_workload,\n",
    "#                                                                                 distance_between_users,storage_capacity,edge_fidelity_range,delat_value,purificaion_scheme]) \n",
    "                                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031be1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def EGR_for_dynamic_population(each_network_topology_file,spike_mean,num_spikes,experiment_repeat,storage_node_selection_scheme):\n",
    "#     for spike_mean in spike_means:\n",
    "#         for network_topology,file_path in each_network_topology_file.items():\n",
    "#             import pdb\n",
    "#             each_storage_each_path_number_value = {}\n",
    "#             network = Network(file_path)\n",
    "            \n",
    "#             for i in range(experiment_repeat):\n",
    "        \n",
    "#                 network = Network(file_path)\n",
    "#                 network.get_user_pairs_over_dynamicly_chaning_population(number_of_user_pairs,distance_between_users,number_of_time_slots)\n",
    "\n",
    "#                 work_load = Work_load(number_of_time_slots,\"time_demands_file.csv\")\n",
    "\n",
    "#                 objective_values = []\n",
    "#                 selected_storage_nodes = []\n",
    "#                 selected_storage_pairs = []\n",
    "\n",
    "#                 #nx.draw(network.g,with_labels=True)\n",
    "#                 # plt.show()\n",
    "#                 network.reset_pair_paths()\n",
    "#                 pairs = []\n",
    "#                 print(\"network.each_t_user_pairs\",network.each_t_user_pairs)\n",
    "#                 for t,user_pairs in network.each_t_user_pairs.items():            \n",
    "#                     for user_pair in user_pairs:\n",
    "#                         if user_pair not in pairs:\n",
    "#                             pairs.append(user_pair)\n",
    "#                 network.get_each_user_pair_real_paths(pairs)\n",
    "\n",
    "#                 import pdb\n",
    "#                 #pdb.set_trace()\n",
    "\n",
    "\n",
    "#                 \"\"\"select and add new storage pairs\"\"\"\n",
    "\n",
    "#                 for number_of_storages in range(7):\n",
    "#                     print(\"for number of storages round  \",number_of_storages)\n",
    "#                     network.get_new_storage_pairs(number_of_storages,storage_node_selection_scheme)\n",
    "#                     work_load.reset_variables()\n",
    "#                     work_load.set_each_time_requests(network.each_t_user_pairs,network.storage_pairs)\n",
    "#                     work_load.set_each_time_real_requests(network.each_t_user_pairs)\n",
    "#                     \"\"\"with new storage pairs, we will check the solution for each number of paths(real and virtual)\"\"\"\n",
    "#                     for num_paths in range(3,4):\n",
    "\n",
    "#                         path_counter_id = 0\n",
    "#                         #print(\"network.storage_pairs\",network.storage_pairs)\n",
    "#                         #import pdb\n",
    "#                         #pdb.set_trace()\n",
    "#                         network.get_each_user_pair_real_paths(network.storage_pairs)\n",
    "#                         if number_of_storages==1:\n",
    "#                             number_of_storages = 2\n",
    "\n",
    "#                         \"\"\"first we add the real paths between storage pairs\"\"\"\n",
    "\n",
    "#                         print(\"for iteration %s storage %s and path number %s\"%(i,number_of_storages,num_paths))\n",
    "#                         for storage_pair in network.storage_pairs:\n",
    "#                             #print(\"going to get real paths between storage pair \",storage_pair)\n",
    "#                             paths = network.get_real_path(storage_pair,num_paths)\n",
    "#                             #print(\"got paths\",paths)\n",
    "#                             for path in paths:\n",
    "#                                 network.set_each_path_length(path_counter_id,path)\n",
    "#                                 network.set_of_paths[path_counter_id] = path\n",
    "#                                 network.each_path_path_id[tuple(path)] = path_counter_id\n",
    "#                                 try:\n",
    "#                                     network.each_request_real_paths[storage_pair].append(path_counter_id)\n",
    "#                                 except:\n",
    "#                                     network.each_request_real_paths[storage_pair]=[path_counter_id]\n",
    "#                                 try:\n",
    "#                                     network.each_storage_real_paths[storage_pair].append(path)\n",
    "#                                 except:\n",
    "#                                     network.each_storage_real_paths[storage_pair]=[path]\n",
    "#                                 #print(\"*** we used path_counter_id\",path_counter_id)\n",
    "#                                 path_counter_id+=1\n",
    "\n",
    "#                         across_all_time_slots_pairs = []\n",
    "#                         for t,user_pairs in network.each_t_user_pairs.items():\n",
    "#                             for user_pair in user_pairs:\n",
    "#                                 if user_pair not in across_all_time_slots_pairs:\n",
    "#                                     across_all_time_slots_pairs.append(user_pair)\n",
    "#                         all_sub_paths = []\n",
    "#                         for user_pair in across_all_time_slots_pairs:\n",
    "#                             paths = network.get_real_path(user_pair,num_paths)\n",
    "#                             #print(\"we got real paths for user pair\",user_pair,paths)\n",
    "#                             for path in paths:\n",
    "#                                 network.set_of_paths[path_counter_id] = path\n",
    "#                                 network.set_each_path_length(path_counter_id,path)\n",
    "#                                 network.each_path_path_id[tuple(path)] = path_counter_id\n",
    "#                                 try:\n",
    "#                                     network.each_request_real_paths[user_pair].append(path_counter_id)\n",
    "#                                 except:\n",
    "#                                     network.each_request_real_paths[user_pair]=[path_counter_id]\n",
    "                                \n",
    "#                                 path_counter_id+=1\n",
    "    \n",
    "#                             for storage_pair in network.storage_pairs:\n",
    "#                                 \"\"\"add one new path to the previous paths\"\"\"\n",
    "#                                 for real_sub_path in network.each_storage_real_paths[storage_pair]:\n",
    "                                    \n",
    "#                                     paths = network.get_paths_to_connect_users_to_storage(user_pair,real_sub_path,num_paths)\n",
    "#     #                               \n",
    "#                                     this_sub_path_id = network.each_path_path_id[tuple(real_sub_path)]\n",
    "                                    \n",
    "\n",
    "#                                     for path in paths:\n",
    "#                                         network.set_each_path_length(path_counter_id,path)\n",
    "#                                         \"\"\"we remove the sub path that is connecting two storage pairs \n",
    "#                                         from the path because we do not want to check the edge capacity for the edges of this subpath\"\"\"\n",
    "#     #                                     print(\"we set length %s for path %s having sub path %s with ID %s\"%(len(path),path,real_sub_path,this_sub_path_id))\n",
    "#                                         try:\n",
    "#                                             network.each_request_virtual_paths_include_subpath[user_pair][this_sub_path_id].append(path_counter_id)\n",
    "#                                         except:\n",
    "#                                             try:\n",
    "#                                                 network.each_request_virtual_paths_include_subpath[user_pair][this_sub_path_id]=[path_counter_id]\n",
    "#                                             except:\n",
    "#                                                 network.each_request_virtual_paths_include_subpath[user_pair]={}\n",
    "#                                                 network.each_request_virtual_paths_include_subpath[user_pair][this_sub_path_id]=[path_counter_id]\n",
    "#                                         if this_sub_path_id not in all_sub_paths:\n",
    "#                                             all_sub_paths.append(this_sub_path_id)\n",
    "#                                         path = network.remove_storage_pair_real_path_from_path(real_sub_path,path)\n",
    "#                                         #print(\"and after removing sub path we have \",path,real_sub_path,len(path))\n",
    "#                                         network.set_of_paths[path_counter_id] = path\n",
    "#                                         try:\n",
    "#                                             network.each_request_virtual_paths[user_pair].append(path_counter_id)\n",
    "#                                         except:\n",
    "#                                             network.each_request_virtual_paths[user_pair]=[path_counter_id]\n",
    "#                                         #print(\"*** we used path_counter_id\",path_counter_id)\n",
    "#                                         path_counter_id+=1\n",
    "\n",
    "\n",
    "#                                     for pair in network.storage_pairs:\n",
    "#                                         network.each_request_virtual_paths[pair]=[]\n",
    "\n",
    "#                                     #print(\"for user pair %s to storage pair %s we got real paths and it is:\"%(user_pair,storage_pair))\n",
    "\n",
    "#                         if number_of_storages==0:\n",
    "#                             for t,pairs in network.each_t_user_pairs.items():\n",
    "#                                 for pair in pairs:\n",
    "#                                     network.each_request_virtual_paths[pair]=[]\n",
    "\n",
    "#                         for j in network.storage_pairs:\n",
    "#                             for sub_path_id in all_sub_paths:\n",
    "#                                 try:\n",
    "#                                     network.each_request_virtual_paths_include_subpath[j][sub_path_id] = []\n",
    "#                                 except:\n",
    "#                                     network.each_request_virtual_paths_include_subpath[j]={}\n",
    "#                                     network.each_request_virtual_paths_include_subpath[j][sub_path_id] = []\n",
    "#                         for t in range(number_of_time_slots):\n",
    "#                             for k in work_load.each_t_requests[t]:\n",
    "#                                 try:\n",
    "#                                     if k in list(network.each_request_virtual_paths_include_subpath.keys()):\n",
    "#                                         pass\n",
    "#                                     else:\n",
    "#                                         network.each_request_virtual_paths_include_subpath[k]= {}\n",
    "#                                 except:\n",
    "#                                     network.each_request_virtual_paths_include_subpath[k]= {}\n",
    "\n",
    "#                         \"\"\"we set the capacity of each storage node\"\"\"\n",
    "\n",
    "#                         network.set_storage_capacity()\n",
    "\n",
    "#                         \"\"\"we add new storage pairs as our user pairs and set the demand for them zero\"\"\"\n",
    "\n",
    "#                         work_load.set_storage_pairs_as_user_pairs(network.storage_pairs)\n",
    "\n",
    "#                         \"\"\"we print all variables to check the variables and values\"\"\"\n",
    "\n",
    "#                         life_time_set = [1000,2]\n",
    "#                         for life_time in life_time_set:\n",
    "#                             \"\"\"solve the optimization\"\"\"        \n",
    "#                             try:\n",
    "#                                 objective_value=0\n",
    "#                                 try:\n",
    "#                                     objective_value,each_inventory_per_time_usage = CPLEX_maximizing_entanglement_generation(network,work_load,life_time,i)\n",
    "#                                 except ValueError:\n",
    "#                                     print(ValueError)\n",
    "#                                     pass\n",
    "#                                 objective_values.append(objective_value)\n",
    "#                                 if 0<objective_value<distance_between_users-1:\n",
    "                                    \n",
    "\n",
    "#                                 print(\"the objective value for %s storage nodes and %s paths between each pair of nodes is %s\"%(number_of_storages,num_paths,objective_value))\n",
    "\n",
    "#     #                             print(each_inventory_per_time_usage)\n",
    "#                                 #time.sleep(10)\n",
    "#                                 for storage_pair,t_saved_EPRs in each_inventory_per_time_usage.items():\n",
    "#                                     for t ,EPRs in t_saved_EPRs.items():\n",
    "#                                         with open(inventory_utilization_results_file_path, 'a') as newFile:                                \n",
    "#                                             newFileWriter = csv.writer(newFile)\n",
    "#                                             newFileWriter.writerow([topology,number_of_storages,num_paths,i,life_time,storage_pair,t,EPRs,storage_node_selection_scheme]) \n",
    "\n",
    "#                                 with open(results_file_path, 'a') as newFile:                                \n",
    "#                                     newFileWriter = csv.writer(newFile)\n",
    "#                                     newFileWriter.writerow([topology,number_of_storages,num_paths,life_time,objective_value,i,storage_node_selection_scheme]) \n",
    "\n",
    "#                             except ValueError:\n",
    "#                                 #pass\n",
    "#                                 print(ValueError)\n",
    "#                 print(\"until the %s th iteration we have %s\"%(i,each_storage_each_path_number_value)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f6746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
